# -*- coding: utf-8 -*-
"""Desafio_Phoebus_Aldenis.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1fqVvkvXxJwEt31U6sEYztLf8acZd_7Hx

#Desafio - Engenharia de Dados - PHOEBUS

###Candidato: Aldenis Everton Alves Guilherme de França

##1.1 PROGRAMAÇÃO

####Implementar ordenação por BubbleSort
"""

def bubbleSort(array):
  itens = len(array)-1
  ordem = False
  while not ordem:
    ordem = True
    for i in range(itens):
      if array[i] > array[i+1]:
        array[i],array[i+1] = array[i+1],array[i]
        ordem = False
        print(array)

  return array

array = [5, 9, 54, 12, 7, 5, 6, 1]
bubbleSort(array)

"""##2.1 INSTACART

###Importação de Bibliotecas
"""

# Bibliotecas para modelagem de dados
import pandas as pd
import numpy as np

# Bibliotecas para análises gráficas
import matplotlib.pyplot as plt

"""###Importação das Bases de Dados"""

# Leitura das bases de dados.

path = 'order_products__train.csv'
path2 = 'products.csv'

df_vendas = pd.read_csv(path, sep=',', encoding='ISO-8859-1')
df_prod = pd.read_csv(path2, sep=',', encoding='ISO-8859-1')

"""###Construção da Tabela Única"""

# Integração dos dados das tabelas de vendas e produtos.

df_completo = pd.merge(df_vendas, df_prod, how='left', on=['product_id'])

"""###Análise Exploratória dos Dados"""

# Visualização parcial do dataset completo.

df_completo.head(10)

# Relação dos 10 produtos mais vendidos.

df_completo.groupby('product_name').size().nlargest(10)

# Visualização Gráfica dos 10 produtos mais vendidos (Gráfico de Barras).

dez_maiores_bar = df_completo.groupby('product_name').size().nlargest(10).plot(kind='bar',xlabel='Nome do Produto',ylabel='Quantidade de Vendas',
                                                                           title='Os 10 Produtos Mais Vendidos pelo Nome do Produto',figsize=(13,10),color='b')

# Visualização Gráfica dos 10 produtos mais vendidos (Gráfico de Pizza).

dez_maiores_pie = df_completo.groupby('product_name').size().nlargest(10).plot(kind='pie',title='Os 10 Produtos Mais Vendidos pelo Nome do Produto',figsize=(13,10))

# Cálculo da Média dos Produtos por compra.

print('Média de Produtos x Compra:')
med_prod_comp = df_completo.groupby('order_id')['product_id'].size().mean()
print(f'\n{med_prod_comp}')

"""##2.2 TITANIC

###Importação de Bibliotecas
"""

# Bibliotecas para modelagem de dados
import pandas as pd
import numpy as np

# Bibliotecas para análises gráficas
import matplotlib.pyplot as plt
import seaborn as sns

# Bibliotecas/classes para tratamento dos dados categóricos
from sklearn.preprocessing import LabelEncoder
from sklearn.preprocessing import OneHotEncoder

# Bibliotecas/classes para normalização dos dados
from sklearn.preprocessing import MinMaxScaler
from sklearn.preprocessing import Normalizer
from sklearn.preprocessing import StandardScaler
from sklearn.preprocessing import RobustScaler

# Bibliotecas/classes para divisão de treino e teste
from sklearn.model_selection import train_test_split

# Bibliotecas/classes para os modelos
from sklearn import tree
from sklearn import model_selection
from sklearn.metrics import classification_report
from sklearn.ensemble import RandomForestClassifier

"""###Importação da Base de Dados"""

# Leitura das bases de dados.

data = 'train.csv'
df_train = pd.read_csv(data, sep=',', encoding='ISO-8859-1')

"""###Análise Exploratória dos Dados

#####Dimensão dos Dados
"""

# Especificação do número de linhas e colunas da base de dados.

print(f'QUANTIDADE DE LINHAS: {df_train.shape[0]}\n')
print(f'QUANTIDADE DE COLUNAS: {df_train.shape[1]}')

"""#####Apresentação dos Dados"""

# Visualização parcial da base de dados.

df_train.head()

# Nomes das colunas da base de dados.

df_train.columns

"""#####Informações Estatísticas dos Dados"""

# Métricas estatísticas da base de dados.

df_train.describe()

# Quantidade de dados nulos em cada coluna da base de dados.

df_train.isnull().sum()

# Tipos de variáveis de cada coluna da base de dados.

df_train.info()

# Agrupamento de Dados por classes.

print("AGRUPAMENTO de alguns dados por classes:\n")

print('Média de Classe por Sexo:')
sex_class = df_train.groupby('Sex')['Pclass'].mean()
print(sex_class)
print('')

print(df_train.groupby('Survived').size())
print('')

print(df_train.groupby('Cabin').size())
print('')

#Construção dos gráficos boxplot de cada classe numérica.

for nome_col in df_train.columns:
  if df_train[nome_col].dtype != object:
    df_train[nome_col].plot(kind='box', subplots=True, layout=(4,4), sharex=False, sharey=False, figsize=(18,18))
    plt.show()

print("HISTOGRAMAS dos dados de cada classe:\n")

df_train.hist(layout=(3,3),figsize=(15,15))
plt.savefig('histogramas.jpg',dpi=200)

#Construção da matriz de correlação entre as classes do df_train.

print('Matriz de Correlação - HEATMAP das Variáveis:\n')
plt.figure(figsize=(10,10))
ax = sns.heatmap(df_train.corr(), cmap='Blues', annot=True)
plt.savefig('heatmap_df.jpg',dpi=200)

"""###Pré-processamento dos Dados

#####Remoção de colunas
"""

# Remoção das colunas Survived, Name e PassengerId.

y = df_train.Survived
w = df_train.PassengerId
k = df_train.Name
df_train.drop(['Survived','Name','PassengerId'], axis=1, inplace=True)

"""#####Tratamento dos Dados Nulos"""

# Substituindo os valores nulos pela mediana ou por -1 (não informado).

col_null = [['Age'],['Cabin','Embarked']]

for i in range(0,len(col_null)):
  for col in col_null[i]:
    if i == 0:
      df_train[col].fillna(df_train[col].median(),inplace=True)
    elif i == 1:
      df_train[col].fillna(-1,inplace=True)

# Quantidade de dados nulos após o tratamento em cada coluna da base de dados.

df_train.isnull().sum()

"""#####Conversão dos Dados Categóricos em Numéricos"""

# Conversão dos dados das colunas object em strings.

df_train['Sex'] = df_train['Sex'].astype(str)
df_train['Ticket'] = df_train['Ticket'].astype(str)
df_train['Cabin'] = df_train['Cabin'].astype(str)
df_train['Embarked'] = df_train['Embarked'].astype(str)

# Aplicação da classe LabelEncoder às colunas categóricas
# para convertê-las em numéricas.

le = LabelEncoder()
for col in df_train.columns:
  if df_train[col].dtype == object:
    df_train[col] = le.fit_transform(df_train[col])
  else:
    pass

# Aplicação da classe One-Hot-Encoder às classes Pclass, Sex e Embarked.

onehotencoder = OneHotEncoder()
K = onehotencoder.fit_transform(df_train.Pclass.values.reshape(-1,1)).toarray()
W = onehotencoder.fit_transform(df_train.Sex.values.reshape(-1,1)).toarray()
Z = onehotencoder.fit_transform(df_train.Embarked.values.reshape(-1,1)).toarray()

# Conversão dos arrays K, W e Z OneHot para um Dataframe cada e adição das colunas desses 
# Dataframes (dfOneHot1, dfOneHot2 e dfOneHot3) ao nosso df_train.

dfOneHot1 = pd.DataFrame(K, columns= ['Class_'+str(int(i)) for i in range(K.shape[1])])
dfOneHot2 = pd.DataFrame(W, columns= ['Sex_'+str(int(i)) for i in range(W.shape[1])])
dfOneHot3 = pd.DataFrame(Z, columns= ['Embarked_'+str(int(i)) for i in range(Z.shape[1])])

df_train['Class_1'] = dfOneHot1['Class_0']
df_train['Class_2'] = dfOneHot1['Class_1']
df_train['Class_3'] = dfOneHot1['Class_2']

df_train['SEX_F'] = dfOneHot2['Sex_0']
df_train['SEX_M'] = dfOneHot2['Sex_1']

df_train['Embarked_C'] = dfOneHot3['Embarked_1']
df_train['Embarked_Q'] = dfOneHot3['Embarked_2']
df_train['Embarked_S'] = dfOneHot3['Embarked_3']
df_train['Embarked_NAO_INFOR'] = dfOneHot3['Embarked_0']

df_train.drop(['Pclass','Sex','Embarked'], axis=1, inplace=True)

print(df_train.shape)
df_train.head()

df_train.info()

"""#####Normalização dos Dados"""

# Normalização dos dados utilizando-se a classe MinMax do sklearn.

# obtendo os valores do dataset
X = df_train.values

# normaliza os dados
scaler = MinMaxScaler() 
normalizedX = scaler.fit_transform(X)

print('DADOS NORMALIZADOS\n')
np.set_printoptions(precision=3)
print(normalizedX)

"""###Modelagem dos Dados

#####Divisão em Treino e Teste
"""

# Trabalhar com uma semente fixa para geração de números aleatórios.
seed = 12

# Divisão dos dados em treino e teste.
X_train, X_test, y_train, y_test = train_test_split(normalizedX, y, test_size = 0.3, random_state = seed)

X_train

print(np.histogram(y_train, bins=2))
y_train.plot.hist(grid=True, bins=2, rwidth=0.9, color='#607c8e')
plt.title('Dados Label Base de Treino')
plt.xlabel('Quantidade')
plt.ylabel('Label')
plt.grid(axis='y', alpha=0.75)

X_test

y_test

"""####Aplicação dos Modelos

#####Árvore de Decisão
"""

# Implementação do Modelo de Árvore de Decisão

# Semente de números aleatórios
seed = 7
num_trees = 5000
max_features = 7

# Número de folds através do metodo k-fold
kfold = model_selection.StratifiedKFold(n_splits=10, random_state=seed)

# Criando a árvore de decisão
clf = tree.DecisionTreeClassifier(criterion='entropy', random_state=seed)

# Treinamento da árvore de decisão em dez folds
results_ad = model_selection.cross_val_score(clf, X_train, y_train, cv=kfold)
clf = clf.fit(X_train, y_train)

print('Decision Tree Folds', results_ad, '\n\nMédia do Treinamento: ',results_ad.mean())
print('\nAcurácia do Treinamento: ', clf.score(X_train, y_train))
print('\nAcurácia do Teste: ', clf.score(X_test, y_test))

"""#####Random Forest"""

# Implementação do Modelo de Classificação Random Forest

# Criando o classificador Random Forest
model_rf = RandomForestClassifier(n_estimators=num_trees, max_features=max_features, random_state=seed)

# Treinamento do Random Forest em dez folds
results_rf = model_selection.cross_val_score(model_rf, X_train, y_train, cv=kfold)
model_rf = model_rf.fit(X_train, y_train)

print("Random Forest Folds:", results_rf, "\n\nMédia do Treinamento: " ,results_rf.mean())
print("\nAcurácia do Treinamento: ", model_rf.score(X_train, y_train))
print("\nAcurácia do Teste: ", model_rf.score(X_test, y_test))

"""#####Análise Gráfica Comparativa"""

# Plotagem dos Boxplots dos Resultados

# Árvore de Decisão
plt.boxplot(results_ad, patch_artist=True) 
plt.show()

# Random Forest
plt.boxplot(results_rf, patch_artist=True)
plt.show()